{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Hooks\n",
    "\n",
    "Let's start by importing. I also set a seed value to allow reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from collections import OrderedDict \n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed\n",
    "seed_value = 0\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self, output_layers, *args):\n",
    "        super().__init__(*args)\n",
    "        self.output_layers = output_layers\n",
    "        \n",
    "        # Pretrained model we will be using\n",
    "        self.pretrained = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Where the output of the hooks will be stored\n",
    "        self.selected_out = OrderedDict()\n",
    "\n",
    "        # Register the forward hook on the given output layers\n",
    "        # Forward Hook is triggered every time after the method foward of the Pytorch AutoGrad Function grad_fn\n",
    "        # We can modify the output by returning the modified output from the hook. \n",
    "        # Using forward_pre_hook the user can modify the input but returning the modified input value as a tuple or just a single modified value in the hook.\n",
    "        self.fhooks = []\n",
    "        for i,l in enumerate(list(self.pretrained._modules.keys())):\n",
    "            if i in self.output_layers:\n",
    "                self.fhooks.append(getattr(self.pretrained,l).register_forward_hook(self.custom_forward_hook(l)))\n",
    "        \n",
    "        self.bhooks = []\n",
    "\n",
    "    def custom_forward_hook(self, layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.selected_out[layer_name] = output\n",
    "\n",
    "        return hook\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pretrained(x)\n",
    "        return out, self.selected_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Initialize the model and the target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 -> layer4\n",
    "# 8 -> avgpool\n",
    "model = NewModel(output_layers = [7,8])\n",
    "\n",
    "# Random array with the dimension of the layer 4\n",
    "target_ft = torch.rand((2048,8,8))\n",
    "\n",
    "learning_rate = 0.00001\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = Adam(params, lr=learning_rate)\n",
    "lr_scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "print(target_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Image\n",
    "batch_size = 1\n",
    "channels = 3\n",
    "height = 256\n",
    "width = 256\n",
    "image_array = np.random.randint(0, 256, size=(batch_size, channels, height, width)).astype('float32')\n",
    "x = torch.from_numpy(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # One pass through the model\n",
    "    out, layerout = model(x)\n",
    "    layer4out = layerout['layer4']\n",
    "                        \n",
    "    # Dummy loss\n",
    "    final_loss = 0 # torch.sum((label-out)**2)\n",
    "    layer_loss = -torch.sum(layer4out-target_ft)\n",
    "\n",
    "    total_loss = final_loss + layer_loss\n",
    "    total_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    lr_scheduler.step()\n",
    "    print(total_loss)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
